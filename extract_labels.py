# extract_labels.py ‚Äî –ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–∞—Ä—Å–µ—Ä–æ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
import re
import csv
import sys
from docx import Document
from normalize import normalize_headings, normalize_scene_heading_strict

# ===== –£–õ–£–ß–®–ï–ù–ù–´–ô REGEX –î–õ–Ø –†–ê–ó–ë–ò–í–ö–ò –ù–ê –°–¶–ï–ù–´ =====
COMPREHENSIVE_SPLIT = re.compile(
    r'(?=^\s*'
    r'(?:'
    # –ë–õ–û–ö 1: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (—Å –¥–µ—Ñ–∏—Å–æ–º)
    r'(?:\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
    r'(?:\d{1,2}-[–ïE]\.?)?\s*'
    r'(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?|–ò/–ù|I/E)\s+'
    r'[^\n]{2,140}?'
    r'\s*[-‚Äì‚Äî]\s*'
    r'(?:–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|EVENING|MORNING|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)(?:\s+\d+)?'
    r'|'
    # –ë–õ–û–ö 2: –ë–ï–ó –¥–µ—Ñ–∏—Å–∞ (—Ç–æ—á–∫–∞ –∏–ª–∏ –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –≤—Ä–µ–º–µ–Ω–µ–º)
    r'(?:\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
    r'(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s*'  # –±—ã–ª–æ \s+, —Å—Ç–∞–ª–æ \s*
    r'[^\n]{2,200}?'
    r'\.?\s+'
    r'(?:–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)(?:\s+\d+)?'
    r'\.?\s*$'
    r'|'
    # –ë–õ–û–ö 3: –°–ª–∏—Ç–Ω–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ "–õ–ï–°.–û–ü–£–®–ö–ê –ù–û–ß–¨"
    r'(?:\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
    r'(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s*'  # –±—ã–ª–æ \s+, —Å—Ç–∞–ª–æ \s*
    r'[A-Z–ê-–Ø–Å]+\.[A-Z–ê-–Ø–Å][^\n]{1,100}?'
    r'\s+(?:–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)(?:\s+\d+)?'
    r'|'
    # –ë–õ–û–ö 4: –ù–æ–º–µ—Ä.—Ç–∏–ø –õ–û–ö–ê–¶–ò–Ø - –í–†–ï–ú–Ø
    r'\d+\.\s*(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s+[^\n]{2,120}\s*[-‚Äì‚Äî]\s*'
    r'(?:–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)(?:\s+\d+)?'
    r'|'
    # –ë–õ–û–ö 5: –°–ª—É–∂–µ–±–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
    r'(?:–°–¶–ï–ù–ê|–°–ï–†–ò–Ø|–¢–ò–¢–†–´)\s*\d*'
    r'|'
    # –ë–õ–û–ö 6: –§–æ—Ä–º–∞—Ç "–Ω–æ–º–µ—Ä. —Ç–∏–ø. –õ–û–ö–ê–¶–ò–Ø. –í–†–ï–ú–Ø" (—Å —Ç–æ—á–∫–∞–º–∏ –≤–º–µ—Å—Ç–æ –¥–µ—Ñ–∏—Å–æ–≤)
    r'\d+\.\s*(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s*'  # –±—ã–ª–æ \s+, —Å—Ç–∞–ª–æ \s*
    r'[^\n]{2,200}?\.\s*'
    r'(?:–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)\b'
    r'|'
    # –ë–õ–û–ö 7: –§–æ—Ä–º–∞—Ç "–Ω–æ–º–µ—Ä. —Ç–∏–ø. –õ–û–ö–ê–¶–ò–Ø. –ü–û–î–õ–û–ö–ê–¶–ò–Ø" (–±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏, –¥–ª—è —Å—Ü–µ–Ω 12, 13)
    r'(?:\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
    r'(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s*'
    r'[A-Z–ê-–Ø–Å][^\n.]{2,100}?\.[A-Z–ê-–Ø–Å][^\n]{2,100}?'
    r'(?:\s*/\s*[A-Z–ê-–Ø–Å][^\n]{2,100}?)?'
    r'|'
    # –ë–õ–û–ö 8: –°–ª–∏—Ç–Ω–æ–µ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ "–Ω–æ–º–µ—Ä. —Ç–∏–ø.–õ–û–ö–ê–¶–ò–Ø" –∏–ª–∏ —Å / (–¥–ª—è 10, 15)
    r'(?:\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
    r'(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s*'
    r'[A-Z–ê-–Ø–Å][^\n\s]{4,120}?(?:\s*/\s*[A-Z–ê-–Ø–Å][^\n]{2,100}?)?'
    r'(?=\s*(?:–î–ï–ù–¨|–ù–û–ß–¨|\n))'
    r'|'
    # –ë–õ–û–ö 9: "–Ω–æ–º–µ—Ä. –ù–ê–¢.–£ –¶–ò–†–ö–ê. –î–ï–ù–¨" (—Ç–æ—á–∫–∏ –≤–º–µ—Å—Ç–æ –¥–µ—Ñ–∏—Å–æ–≤, –¥–ª—è 3, 4, 7)
    r'\d+\.\s*(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s*'
    r'[A-Z–ê-–Ø–Å][^\n.]{2,80}?\.[A-Z–ê-–Ø–Å][^\n]{2,80}?'
    r'(?:\s*\.\s*(?:–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT)\b)?'
    r')'
    r')',
    re.IGNORECASE | re.MULTILINE
)

def split_scenes(text: str):
    """–†–∞–∑–±–∏–≤–∫–∞ —Å –º–Ω–æ–≥–æ–ø–∞—Ç—Ç–µ—Ä–Ω–Ω—ã–º regex + —Ñ–∏–ª—å—Ç—Ä –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤"""
    parts = re.split(COMPREHENSIVE_SPLIT, text)
    scenes = []
    for p in parts:
        p = p.strip()
        word_count = len(p.split())
        # –ú–∏–Ω–∏–º—É–º 5 —Å–ª–æ–≤ –ò–õ–ò –Ω–∞–ª–∏—á–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        has_action = bool(re.search(
            r'\b(–≤—Ö–æ–¥–∏—Ç|–≤—ã—Ö–æ–¥–∏—Ç|–≥–æ–≤–æ—Ä–∏—Ç|—Å–º–æ—Ç—Ä–∏—Ç|–±–µ—Ä—ë—Ç|–∏–¥—ë—Ç|—Å–∞–¥–∏—Ç—Å—è|—Å—Ç–æ–∏—Ç|–æ—Ç–∫—Ä—ã–≤–∞–µ—Ç|–∑–∞–∫—Ä—ã–≤–∞–µ—Ç)\b',
            p, re.IGNORECASE
        ))
        if word_count >= 5 or (word_count >= 3 and has_action):
            scenes.append(p)
    return scenes

# ===== –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´ –î–õ–Ø –ü–ê–†–°–ò–ù–ì–ê –ó–ê–ì–û–õ–û–í–ö–û–í =====
HEADER_PATTERNS = [
    # –ü–∞—Ç—Ç–µ—Ä–Ω 1: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å –¥–µ—Ñ–∏—Å–æ–º "1-2. –ò–ù–¢. –õ–û–ö–ê–¶–ò–Ø - –ù–û–ß–¨"
    re.compile(
        r'^\s*(?P<scene_no>\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
        r'(?P<period>\d{1,2}-[–ïE]\.?)?\s*'
        r'(?P<place_type>–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s+'
        r'(?P<location>[^-‚Äì‚Äî:\n]{2,140}?)\s*[-‚Äì‚Äî]\s*'
        r'(?P<tod>–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)(?:\s+\d+)?',
        re.IGNORECASE
    ),
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω 2: –ë–ï–ó –¥–µ—Ñ–∏—Å–∞ "1-2. –ò–ù–¢. –õ–û–ö–ê–¶–ò–Ø –ù–û–ß–¨"
    re.compile(
        r'^\s*(?P<scene_no>\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
        r'(?P<period>\d{1,2}-[–ïE]\.?)?\s*'
        r'(?P<place_type>–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s+'
        r'(?P<location>(?:[A-Z–ê-–Ø–Å][^\n]{0,100}?\.)?[A-Z–ê-–Ø–Å][^\n]{1,100}?)'
        r'\s+(?P<tod>–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)(?:\s+\d+)?\.?\s*$',
        re.IGNORECASE | re.MULTILINE
    ),
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω 3: –°–ª–∏—Ç–Ω–æ–µ "–õ–ï–°.–û–ü–£–®–ö–ê –ù–û–ß–¨"
    re.compile(
        r'^\s*(?P<scene_no>\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
        r'(?P<place_type>–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s+'
        r'(?P<location>[A-Z–ê-–Ø–Å][^\s]{2,40}\.[A-Z–ê-–Ø–Å][^\s]{2,80}|[A-Z–ê-–Ø–Å][^\n]{2,100}?)'
        r'\s+(?P<tod>–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)(?:\s+\d+)?',
        re.IGNORECASE
    ),
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω 4: "–Ω–æ–º–µ—Ä.—Ç–∏–ø –õ–û–ö–ê–¶–ò–Ø - –í–†–ï–ú–Ø" (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
    re.compile(
        r'^\s*(?P<scene_no>\d+)\.\s*'
        r'(?P<place_type>–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)?\s*'
        r'(?P<location>[^-‚Äì‚Äî\n]{2,120}?)\s*[-‚Äì‚Äî]\s*'
        r'(?P<tod>–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|–†–ï–ñ–ò–ú)\b',
        re.IGNORECASE
    ),
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω 5: "–Ω–æ–º–µ—Ä. —Ç–∏–ø. –õ–û–ö–ê–¶–ò–Ø. –í–†–ï–ú–Ø" (—Å —Ç–æ—á–∫–∞–º–∏) ‚Äî –ö–õ–Æ–ß–ï–í–û–ô!
    re.compile(
        r'^\s*(?P<scene_no>\d+)\.\s*'
        r'(?P<place_type>–ò–ù–¢\.|–ù–ê–¢\.|INT\.|EXT\.)\s*'   # \s* –≤–º–µ—Å—Ç–æ \s+
        r'(?P<location>[^\n]{2,200}?)\.\s*'
        r'(?P<tod>–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)\b',
        re.IGNORECASE
    ),
    
    re.compile(
        r'^\s*(?P<scene_no>\d+)\.\s*'
        r'(?P<place_type>–ò–ù–¢\.|–ù–ê–¢\.|INT\.|EXT\.)\s*'
        r'(?P<location>[^\n]{2,150}?)\.\s*'
        r'(?P<tod>–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)\b',
        re.IGNORECASE
    ),

    # –ü–∞—Ç—Ç–µ—Ä–Ω 6: –¢–æ–ª—å–∫–æ –õ–û–ö–ê–¶–ò–Ø - –í–†–ï–ú–Ø (–±–µ–∑ –Ω–æ–º–µ—Ä–∞/—Ç–∏–ø–∞)
    re.compile(
        r'^\s*(?P<location>[A-Z–ê-–Ø–Å][^\n-‚Äì‚Äî]{2,100}?)\s*[-‚Äì‚Äî]\s*'
        r'(?P<tod>–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|–†–ï–ñ–ò–ú)\b',
        re.IGNORECASE
    ),

    # –ü–∞—Ç—Ç–µ—Ä–Ω 7: "–Ω–æ–º–µ—Ä. –ò–ù–¢. –õ–û–ö–ê–¶–ò–Ø. –ü–û–î–õ–û–ö–ê–¶–ò–Ø" (–±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏, —Å—Ü–µ–Ω—ã 12, 13)
    re.compile(
        r'^\s*(?P<scene_no>\d+(?:\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?)?\.?\s*'
        r'(?P<place_type>–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s*'
        r'(?P<location>[A-Z–ê-–Ø–Å][^\n.]{2,100}?\.[A-Z–ê-–Ø–Å][^\n]{2,100}?)'
        r'(?:\s*/\s*[A-Z–ê-–Ø–Å][^\n]{2,100}?)?',
        re.IGNORECASE | re.MULTILINE
    ),

    # –ü–∞—Ç—Ç–µ—Ä–Ω 8: "–Ω–æ–º–µ—Ä. –ù–ê–¢.–£ –¶–ò–†–ö–ê. –î–ï–ù–¨" (—Ç–æ—á–∫–∏ + –≤—Ä–µ–º—è, —Å—Ü–µ–Ω—ã 3, 4)
    re.compile(
        r'^\s*(?P<scene_no>\d+)\.\s*'
        r'(?P<place_type>–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s*'
        r'(?P<location>[A-Z–ê-–Ø–Å][^\n.]{2,60}?\.)'
        r'[A-Z–ê-–Ø–Å][^\n]{2,80}?'
        r'(?:\s*\.\s*(?P<tod>–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|–†–ï–ñ–ò–ú|–†–ê–°–°–í–ï–¢)\b)?',
        re.IGNORECASE
    ),
]

def normalize_place_type(raw: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∏–ø–∞ –º–µ—Å—Ç–∞ —Å —É—á—ë—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
    if not raw:
        return ""
    low = raw.lower().replace(".", "").strip()
    mapping = {
        "–∏–Ω—Ç": "–ò–ù–¢.", "int": "INT.", "—ñ": "–ò–ù–¢.", "—ñ–Ω": "–ò–ù–¢.",
        "–Ω–∞—Ç": "–ù–ê–¢.", "ext": "EXT.", "nat": "–ù–ê–¢.",
        "–∏/–Ω": "–ò/–ù", "i/e": "I/E"
    }
    return mapping.get(low, raw.upper())

def normalize_tod(raw: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫"""
    if not raw:
        return ""
    low = raw.lower().strip()
    mapping = {
        "–¥–µ–Ω—å": "–î–ï–ù–¨", "day": "–î–ï–ù–¨",
        "–Ω–æ—á—å": "–ù–û–ß–¨", "night": "–ù–û–ß–¨",
        "–≤–µ—á–µ—Ä": "–í–ï–ß–ï–†", "evening": "–í–ï–ß–ï–†",
        "—É—Ç—Ä–æ": "–£–¢–†–û", "morning": "–£–¢–†–û",
        "—Ä–µ–∂–∏–º": "–†–ï–ñ–ò–ú",  # ‚Üê –î–û–ë–ê–í–õ–ï–ù–û
        "—Ä–∞—Å—Å–≤–µ—Ç": "–†–ê–°–°–í–ï–¢",
        "–∑–∞–∫–∞—Ç": "–ó–ê–ö–ê–¢",
        "—Å—É–º–µ—Ä–∫–∏": "–°–£–ú–ï–†–ö–ò"
    }
    return mapping.get(low, raw.upper())

def heuristic_parse(line: str):
    """–≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
    result = {"scene_no": "", "period": "", "place_type": "", "location": "", "tod": ""}
    
    # –ù–æ–º–µ—Ä —Å—Ü–µ–Ω—ã
    num_match = re.search(r'\b(\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?|\d+)\b', line)
    if num_match:
        result["scene_no"] = num_match.group(1).strip()
    
    # –¢–∏–ø –º–µ—Å—Ç–∞
    type_match = re.search(r'\b(–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?|[–∏—ñ–Ω–∞—Ç]+\.?)\b', line, re.IGNORECASE)
    if type_match:
        result["place_type"] = normalize_place_type(type_match.group(1))
    
    # –í—Ä–µ–º—è —Å—É—Ç–æ–∫ (–†–ê–°–®–ò–†–ï–ù–ù–´–ô –°–ü–ò–°–û–ö)
    tod_match = re.search(
        r'\b(–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|–¥–µ–Ω—å|–Ω–æ—á—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ|DAY|NIGHT|–†–ï–ñ–ò–ú|—Ä–µ–∂–∏–º|–†–ê–°–°–í–ï–¢|—Ä–∞—Å—Å–≤–µ—Ç|–ó–ê–ö–ê–¢|–°–£–ú–ï–†–ö–ò)(?:\s+\d+)?',
        line,
        re.IGNORECASE
    )
    if tod_match:
        result["tod"] = normalize_tod(tod_match.group(1).split()[0])
        # –õ–æ–∫–∞—Ü–∏—è ‚Äî —Ç–µ–∫—Å—Ç –º–µ–∂–¥—É —Ç–∏–ø–æ–º –∏ –≤—Ä–µ–º–µ–Ω–µ–º
        if result["place_type"] and result["tod"]:
            loc_pattern = rf'{re.escape(result["place_type"])}\s*(.+?)\s*[-‚Äì‚Äî:]\s*{re.escape(result["tod"])}'
            loc_match = re.search(loc_pattern, line, re.IGNORECASE)
            if loc_match:
                result["location"] = loc_match.group(1).strip().strip('.')
        elif result["tod"]:
            # –¢–æ–ª—å–∫–æ –≤—Ä–µ–º—è –µ—Å—Ç—å ‚Äî –±–µ—Ä—ë–º –≤—Å—ë –¥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
            loc_match = re.search(r'(.+?)\s*[-‚Äì‚Äî:]\s*' + re.escape(result["tod"]), line, re.IGNORECASE)
            if loc_match:
                result["location"] = loc_match.group(1).strip().strip('.')
    
    return result

def parse_header(scene_text: str):
    """Fuzzy-–ø–∞—Ä—Å–∏–Ω–≥ —Å fallback —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    lines = scene_text.splitlines()
    first_line = lines[0] if lines else scene_text[:200]
    
    # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ –ø–æ—Ä—è–¥–∫—É –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    for pattern in HEADER_PATTERNS:
        m = pattern.search(first_line)
        if m:
            return {
                "scene_no": (m.groupdict().get("scene_no") or "").strip(),
                "period": (m.groupdict().get("period") or "").strip(),
                "place_type": normalize_place_type(m.groupdict().get("place_type") or ""),
                "location": (m.groupdict().get("location") or "").strip().strip('. '),
                "tod": normalize_tod(m.groupdict().get("tod") or "")
            }
    
    # Fallback: —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥
    return heuristic_parse(first_line)

# ===== –†–ê–ó–ú–ï–¢–ö–ê (LABELS) =====
LABEL_RE = re.compile(r'\[\s*(?:Labels|–ú–ï–¢–ö–ò)\s*:\s*([^\]]+)\]', re.IGNORECASE)

MAP_KEY = {
    "v": "violence", "p": "profanity", "s": "sexual", "a": "alcohol_drugs", "sc": "scary",
    "–Ω–∞—Å–∏–ª–∏–µ": "violence", "–±—Ä–∞–Ω—å": "profanity", "—Å–µ–∫—Å": "sexual",
    "–∞–ª–∫–æ–≥–æ–ª—å": "alcohol_drugs", "—Å—Ç—Ä–∞—à–Ω–æ–µ": "scary"
}

NORM_SEV = {
    "none": "None", "mild": "Mild", "moderate": "Moderate", "severe": "Severe",
    "–Ω–µ—Ç": "None", "–ª—ë–≥–∫–æ–µ": "Mild", "–ª–µ–≥–∫–æ–µ": "Mild",
    "—Å—Ä–µ–¥–Ω–µ–µ": "Moderate", "–∂—ë—Å—Ç–∫–æ–µ": "Severe", "–∂–µ—Å—Ç–∫–æ–µ": "Severe"
}

def normalize_text(text: str) -> str:
    text = text.replace("\\[", "[").replace("\\]", "]")
    text = re.sub(r"[ \t]*\\\\\s*$", "", text, flags=re.MULTILINE)
    text = text.replace("{.smallcaps}", "")
    return text

def read_text(path: str) -> str:
    if path.lower().endswith(".docx"):
        doc = Document(path)
        raw = "\n".join(p.text or "" for p in doc.paragraphs)
    else:
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            raw = f.read()
    raw = normalize_text(raw)
    raw = normalize_headings(raw)
    return raw

def parse_label_line(line: str):
    labels = {k: "None" for k in ["violence", "sexual", "profanity", "alcohol_drugs", "scary"]}
    pairs = [p.strip() for p in line.split(",") if p.strip()]
    for p in pairs:
        if "=" not in p:
            continue
        k, v = [x.strip() for x in p.split("=", 1)]
        k = MAP_KEY.get(k.lower(), k.lower())
        v = NORM_SEV.get(v.lower(), v)
        if k in labels:
            labels[k] = v
    return labels

def extract_labels_from_scene(scene_text: str):
    labels = {k: "None" for k in ["violence", "sexual", "profanity", "alcohol_drugs", "scary"]}
    m = LABEL_RE.search(scene_text)
    if m:
        labels = parse_label_line(m.group(1))
    return labels, []

def main(input_path: str, out_csv: str = "labels.csv"):
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤.
    """
    # –ß–∏—Ç–∞–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
    text = read_text(input_path)
    text = normalize_headings(text)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ü–µ–Ω—ã
    scenes = split_scenes(text)
    
    # –û—Ç–∫—Ä—ã–≤–∞–µ–º CSV –¥–ª—è –∑–∞–ø–∏—Å–∏
    with open(out_csv, "w", encoding="utf-8", newline="") as f:
        w = csv.writer(f)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
        w.writerow([
            "scene_no", "place_type", "location", "tod",
            "has_violence", "sev_violence",
            "has_sexual", "sev_sexual",
            "has_profanity", "sev_profanity",
            "has_alcohol_drugs", "sev_alcohol_drugs",
            "has_scary", "sev_scary"
        ])
        
        wrote = 0
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –ª–æ–≥ –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        with open("bad_headers.log", "w", encoding="utf-8") as blog:
            for i, s in enumerate(scenes, 1):
                # ===== –ö–õ–Æ–ß–ï–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç–¥–µ–ª—å–Ω–æ =====
                first_line = s.splitlines()[0] if s.splitlines() else s[:200]
                normalized_header = normalize_scene_heading_strict(first_line)
                
                # –ü–∞—Ä—Å–∏–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                try:
                    meta = parse_header(normalized_header)
                except Exception as e:
                    # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –ø–∞—Ä—Å–∏–Ω–≥–∞
                    blog.write(f"[PARSE ERROR] {first_line}\n")
                    blog.write(f"  Error: {str(e)}\n")
                    meta = {"scene_no": "", "place_type": "", "location": "", "tod": ""}
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ü–µ–Ω—ã
                labels, _ = extract_labels_from_scene(s)
                
                # –í—ã—á–∏—Å–ª—è–µ–º —Ñ–ª–∞–≥–∏ –Ω–∞–ª–∏—á–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                has = {
                    "violence": int(labels["violence"] != "None"),
                    "sexual": int(labels["sexual"] != "None"),
                    "profanity": int(labels["profanity"] != "None"),
                    "alcohol_drugs": int(labels["alcohol_drugs"] != "None"),
                    "scary": int(labels["scary"] != "None"),
                }
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—É—Å—Ç–∞—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ (–Ω–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ò –Ω–µ—Ç –º–µ—Ç–æ–∫)
                meta_empty = not (
                    meta.get("scene_no") or 
                    meta.get("place_type") or 
                    meta.get("location") or 
                    meta.get("tod")
                )
                all_none = sum(has.values()) == 0
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ü–µ–Ω—ã –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö
                if meta_empty and all_none:
                    blog.write(f"[SKIPPED - EMPTY] {first_line[:120]}\n\n")
                    continue
                
                # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å –ø—É—Å—Ç–æ–π –ª–æ–∫–∞—Ü–∏–µ–π
                if meta.get("place_type") and not meta.get("location"):
                    blog.write(f"[WARNING - NO LOCATION] Original: {first_line}\n")
                    blog.write(f"  Normalized: {normalized_header}\n")
                    blog.write(f"  Parsed: {meta}\n\n")
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –≤ CSV
                w.writerow([
                    meta.get("scene_no", ""),
                    meta.get("place_type", ""),
                    meta.get("location", ""),
                    meta.get("tod", ""),
                    has["violence"], labels["violence"],
                    has["sexual"], labels["sexual"],
                    has["profanity"], labels["profanity"],
                    has["alcohol_drugs"], labels["alcohol_drugs"],
                    has["scary"], labels["scary"],
                ])
                wrote += 1
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"‚úÖ OK: –Ω–∞—Ä–µ–∑–∞–Ω–æ —Å—Ü–µ–Ω: {len(scenes)}; –∑–∞–ø–∏—Å–∞–Ω–æ –≤ CSV: {wrote}")
    print(f"üìä –ü—Ä–æ–ø—É—â–µ–Ω–æ (–ø—É—Å—Ç—ã–µ): {len(scenes) - wrote}")
    print(f"üìã –ü—Ä–æ–≤–µ—Ä—å bad_headers.log –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")

if __name__ == "__main__":
    inp = sys.argv[1] if len(sys.argv) > 1 else "annotated_script.docx"
    main(inp)
