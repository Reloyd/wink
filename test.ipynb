{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9b5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pdfplumber\n",
    "from docx import Document\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a21b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    \"violence\": [\"—É–¥–∞—Ä–∏–ª\", \"–∫—Ä–æ–≤—å\", \"—É–±–∏–ª\", \"—Å—Ç—Ä–µ–ª—è–µ—Ç\", \"–ø–∏—Å—Ç–æ–ª–µ—Ç\", \"–¥—Ä–∞–∫–∞\", \"–Ω–æ–∂\", \"—Ç—Ä—É–ø\"],\n",
    "    \"sexual\": [\"–ø–æ—Ü–µ–ª–æ–≤–∞–ª\", \"—Ä–∞–∑–¥–µ–ª–∞—Å—å\", \"–ø–æ—Å—Ç–µ–ª—å\", \"—ç—Ä–æ—Ç\", \"—Å–µ–∫—Å\", \"–∏–Ω—Ç–∏–º\"],\n",
    "    \"profanity\": [\"—á–µ—Ä—Ç\", \"–±–ª–∏–Ω\", \"—Å—É–∫–∞\", \"–≥–∞–¥\", \"–¥–µ—Ä—å–º–æ\", \"–ø–∞–¥–ª–∞\", \"–µ–±\", \"—Ö–µ—Ä\"],\n",
    "    \"alcohol_drugs\": [\"–≤–æ–¥–∫–∞\", \"–ø—å—è–Ω—ã–π\", \"–∞–ª–∫–æ–≥–æ–ª—å\", \"–Ω–∞—Ä–∫–æ—Ç–∏–∫\", \"–∫–æ—Å—è–∫\", \"–≤–∏—Å–∫–∏\", \"–∫—É—Ä–∏—Ç\"],\n",
    "    \"scary\": [\"–∫—Ä–∏—á–∏—Ç\", \"—Ç—Ä—É–ø\", \"–º–æ–Ω—Å—Ç—Ä\", \"—Å—Ç—Ä–∞—à–Ω–æ\", \"–∫—Ä–∏–∫\", \"–∫—Ä–æ–≤—å\", \"—Ç–µ–Ω—å\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "701eae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    if path.endswith(\".pdf\"):\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "    elif path.endswith(\".docx\"):\n",
    "        doc = Document(path)\n",
    "        return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    else:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04dba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥: 16+\n",
      "üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ñ–∞–π–ª—ã: report.json, scene_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "def split_scenes(text):\n",
    "    parts = re.split(r'(–°–¶–ï–ù–ê\\s*\\d*\\.|INT\\.|EXT\\.|–ò–ù–¢\\.|–≠–ö–°–¢\\.)', text, flags=re.IGNORECASE)\n",
    "    scenes = []\n",
    "    current = \"\"\n",
    "    for part in parts:\n",
    "        if re.match(r'(–°–¶–ï–ù–ê|INT|EXT|–ò–ù–¢|–≠–ö–°–¢)', part, flags=re.IGNORECASE):\n",
    "            if current.strip():\n",
    "                scenes.append(current.strip())\n",
    "            current = part\n",
    "        else:\n",
    "            current += \" \" + part\n",
    "    if current.strip():\n",
    "        scenes.append(current.strip())\n",
    "    return [s for s in scenes if len(s.split()) > 3]\n",
    "\n",
    "# ==== –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π —Å—Ü–µ–Ω—ã ====\n",
    "def analyze_scene(scene):\n",
    "    result = {}\n",
    "    scene_lower = scene.lower()\n",
    "    for category, words in keywords.items():\n",
    "        count = sum(w in scene_lower for w in words)\n",
    "        if count == 0:\n",
    "            severity = \"None\"\n",
    "        elif count == 1:\n",
    "            severity = \"Mild\"\n",
    "        elif 2 <= count <= 3:\n",
    "            severity = \"Moderate\"\n",
    "        else:\n",
    "            severity = \"Severe\"\n",
    "        result[category] = {\"count\": count, \"severity\": severity}\n",
    "    return result\n",
    "\n",
    "# ==== –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ ====\n",
    "def get_age_rating(scene_results):\n",
    "    severity_map = {\"None\": 0, \"Mild\": 1, \"Moderate\": 2, \"Severe\": 3}\n",
    "    max_score = 0\n",
    "    for scene in scene_results:\n",
    "        for cat, data in scene.items():\n",
    "            score = severity_map[data[\"severity\"]]\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "    if max_score == 0:\n",
    "        return \"0+\"\n",
    "    elif max_score == 1:\n",
    "        return \"12+\"\n",
    "    elif max_score == 2:\n",
    "        return \"16+\"\n",
    "    else:\n",
    "        return \"18+\"\n",
    "\n",
    "# ==== –∑–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ ====\n",
    "def analyze_script(path):\n",
    "    text = read_file(path)\n",
    "    scenes = split_scenes(text)\n",
    "    results = []\n",
    "    for scene in scenes:\n",
    "        res = analyze_scene(scene)\n",
    "        results.append(res)\n",
    "    age_rating = get_age_rating(results)\n",
    "\n",
    "    # —Å–±–æ—Ä –æ—Ç—á–µ—Ç–∞\n",
    "    report = []\n",
    "    for i, scene in enumerate(scenes):\n",
    "        entry = {\"scene_id\": i + 1, \"text\": scene}\n",
    "        entry.update({k: v[\"severity\"] for k, v in results[i].items()})\n",
    "        report.append(entry)\n",
    "\n",
    "    df = pd.DataFrame(report)\n",
    "    df.to_csv(\"scene_analysis.csv\", index=False)\n",
    "    with open(\"report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"age_rating\": age_rating, \"scenes\": report}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\n‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥: {age_rating}\")\n",
    "    print(f\"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ñ–∞–π–ª—ã: report.json, scene_analysis.csv\")\n",
    "\n",
    "# ==== –∑–∞–ø—É—Å–∫ ====\n",
    "if __name__ == \"__main__\":\n",
    "    path = input(\"–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Å—Ü–µ–Ω–∞—Ä–∏—é (.txt/.pdf/.docx): \").strip()\n",
    "    analyze_script(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
