# debug_split.py ‚Äî –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å—Ü–µ–Ω
import re
from docx import Document
from normalize import normalize_headings

def read_docx(path):
    doc = Document(path)
    return "\n".join(p.text or "" for p in doc.paragraphs)

# –¢–µ–∫—É—â–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –∏–∑ –≤–∞—à–µ–≥–æ –∫–æ–¥–∞
MULTI_PATTERN_SPLIT = re.compile(
    r'(?=^\s*'
    r'(?:'
    r'(?:\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
    r'(?:\d{1,2}-[–ïE]\.?)?\s*'
    r'(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?|–ò/–ù|I/E)?\s*'
    r'[^\n]{3,140}?'
    r'\s*[-‚Äì‚Äî:]\s*'
    r'(?:–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT|EVENING|MORNING)\b'
    r'|'
    r'\d+\.\s*(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s+[^\n]{3,120}\s*[-‚Äì‚Äî]\s*(?:–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT)\b'
    r'|'
    r'(?:\d+\s*-\s*\d+)?\.?\s*[–∏—ñ–Ω—ñ–Ω–∞—Ç]+\.?\s+[^\n]{3,120}\s*[-‚Äì‚Äî]\s*(?:–¥–µ–Ω—å|–Ω–æ—á—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ)\b'
    r'|'
    r'–°–¶–ï–ù–ê\s+\d*'
    r')'
    r')',
    re.IGNORECASE | re.MULTILINE
)

def analyze_splits(path):
    text = read_docx(path)
    text = normalize_headings(text)
    
    # –ù–∞–π—Ç–∏ –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤—Ä—É—á–Ω—É—é (–Ω–µ —á–µ—Ä–µ–∑ split)
    header_pattern = re.compile(
        r'^\s*(?:'
        r'(?:\d+\s*-\s*\d+(?:\s*-\s*[A-Za-z–ê-–Ø–Å])?)?\.?\s*'
        r'(?:\d{1,2}-[–ïE]\.?)?\s*'
        r'(?:–ò–ù–¢\.?|–ù–ê–¢\.?|INT\.?|EXT\.?)\s*'
        r'[^\n]{3,140}?'
        r'\s*[-‚Äì‚Äî]\s*'
        r'(?:–î–ï–ù–¨|–ù–û–ß–¨|–í–ï–ß–ï–†|–£–¢–†–û|DAY|NIGHT)\b'
        r')',
        re.IGNORECASE | re.MULTILINE
    )
    
    all_headers = list(header_pattern.finditer(text))
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (—á–µ—Ä–µ–∑ finditer): {len(all_headers)}\n")
    
    # –†–∞–∑–±–∏—Ç—å —á–µ—Ä–µ–∑ split
    parts = re.split(MULTI_PATTERN_SPLIT, text)
    scenes = [p.strip() for p in parts if len(p.split()) >= 5]
    print(f"üìä –ü–æ–ª—É—á–µ–Ω–æ —Å—Ü–µ–Ω (—á–µ—Ä–µ–∑ split): {len(scenes)}\n")
    
    # –í—ã–≤–µ—Å—Ç–∏ –ø–µ—Ä–≤—ã–µ 10 –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    print("=" * 70)
    print("–ü–ï–†–í–´–ï 10 –ó–ê–ì–û–õ–û–í–ö–û–í (—á–µ—Ä–µ–∑ finditer):")
    print("=" * 70)
    for i, m in enumerate(all_headers[:10], 1):
        header = m.group(0).strip()
        print(f"{i}. {header}")
    
    print("\n" + "=" * 70)
    print("–ü–ï–†–í–´–ï 10 –°–¶–ï–ù (—á–µ—Ä–µ–∑ split):")
    print("=" * 70)
    for i, s in enumerate(scenes[:10], 1):
        first_line = s.splitlines()[0][:120] if s.splitlines() else s[:120]
        print(f"{i}. {first_line}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    if len(all_headers) > len(scenes):
        print(f"\n‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: –ü—Ä–æ–ø—É—â–µ–Ω–æ {len(all_headers) - len(scenes)} –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤!")
        print("–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        print("1. Lookahead –Ω–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö")
        print("2. –§–∏–ª—å—Ç—Ä len(p.split()) >= 5 –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ü–µ–Ω—ã")
        print("3. –ú–µ–∂–¥—É —Å—Ü–µ–Ω–∞–º–∏ –µ—Å—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ç–∏—Ç—Ä—ã, –Ω–æ–º–µ—Ä–∞ —Å–µ—Ä–∏–π)")

if __name__ == "__main__":
    path = input("–ü—É—Ç—å –∫ —Å—Ü–µ–Ω–∞—Ä–∏—é: ").strip()
    analyze_splits(path)
